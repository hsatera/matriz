import streamlit as st
import pandas as pd
import re
import plotly.express as px
import nltk
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
import os
import io

# Baixar recursos do NLTK se necess√°rio.
# A fun√ß√£o nltk.download() j√° verifica se os dados existem antes de baixar.
nltk.download('stopwords', quiet=True)

# --- Configura√ß√£o da P√°gina Streamlit ---
st.set_page_config(layout="wide", page_title="Filtro de Artigos Cient√≠ficos com Resumo")

st.title("üìö MATRIZ: Revis√£o de Escopo")
st.markdown("Use os filtros na barra lateral para encontrar artigos espec√≠ficos e veja o resumo da distribui√ß√£o nos gr√°ficos.")

# --- Carregamento e Pr√©-processamento dos Dados ---
@st.cache_data
def load_data(file_path):
    """
    Carrega os dados do arquivo CSV e preenche valores ausentes.
    """
    df = pd.read_csv(file_path)
    df['notes'] = df['notes'].fillna('')
    df['abstract'] = df['abstract'].fillna('')
    df['keywords'] = df['keywords'].fillna('N√£o informado')
    if 'authors' not in df.columns:
        df['authors'] = 'N√£o informado'
    if 'url' not in df.columns:
        df['url'] = ''
    df['url'] = df['url'].astype(str)
    if 'PDF files' in df.columns:
        df['PDF files'] = df['PDF files'].fillna('').astype(str)
    else:
        df['PDF files'] = ''
    return df

try:
    df = load_data("selecionados.csv")
except FileNotFoundError:
    st.error("Erro: O arquivo 'selecionados.csv' n√£o foi encontrado. Por favor, certifique-se de que o arquivo est√° no mesmo diret√≥rio.")
    st.stop()

# --- Fun√ß√µes de Extra√ß√£o ---
def extract_labels(label_string):
    """
    Extrai as labels de uma string formatada como 'RAYYAN-LABELS: ...'.
    """
    if pd.isna(label_string):
        return []
    match = re.search(r'RAYYAN-LABELS:\s*(.+)', label_string)
    if match:
        labels_part = match.group(1).strip().replace('""', '').replace('{', '').replace('}', '')
        labels = re.findall(r'[^,\|]+', labels_part)
        return [label.strip() for label in labels if label.strip()]
    return []

# Lista fixa de revisores fornecida pelo usu√°rio
all_reviewers = ['andr√©', 'daniela', 'luana', 'henrique', 'carolina', 'humberto', 'mauricio', 'rodrigo']

# Cria uma nova coluna 'Reviewers' no DataFrame original, verificando a presen√ßa dos nomes na coluna 'notes'
df['Reviewers'] = df['notes'].apply(lambda s: [rev for rev in all_reviewers if rev.lower() in s.lower()])
df['Parsed_Labels'] = df['notes'].apply(extract_labels)

# Adiciona uma nova coluna 'Is_Perola' baseada na presen√ßa de 'P√©rola' na coluna 'notes'
df['Is_Perola'] = df['notes'].apply(lambda s: 'Sim' if 'p√©rola' in s.lower() else 'N√£o')

# --- Defini√ß√£o das Op√ß√µes de Filtro ---
# Op√ß√µes para "Sem Label"
SEM_PAIS = "Pa√≠s n√£o especificado"
SEM_METODOLOGIA = "Metodologia n√£o especificada"
SEM_TIPO_ESTUDO = "Tipo de Estudo n√£o especificado"
SEM_EIXO_MATRIZ = "Eixo Matriz n√£o especificado"
SEM_IDIOMA = "Idioma n√£o especificado"

# Listas de op√ß√µes para os gr√°ficos (sem a op√ß√£o "Sem Label")
PAISES = ['Angola', 'Argentina', 'Brasil', 'Cuba', 'Portugal', 'Uruguai']
METODOLOGIAS = ['Estudo misto (quali-quanti)', 'Estudo Qualitativo', 'Estudo quantitativo', 'Revis√£o literatura']
TIPOS_ESTUDO = ['Defini√ß√£o A√ß√µes Coletivas Cuidado', 'Reflex√£o te√≥rica A√ß√µes Coletivas de Cuidado', 'Relato Experi√™ncia A√ß√µes Coletivas de Cuidado']
EIXOS_MATRIZ = ['Doen√ßas cr√¥nicas', 'Sa√∫de Mental', 'Sa√∫de Bucal', 'Inf√¢ncia e Adolesc√™ncia', 'G√™nero e Sexualidade', 'Defici√™ncia Intelectual']
IDIOMAS = ['L√≠ngua Espanhola', 'L√≠ngua Inglesa', 'L√≠ngua Portuguesa']
PEROLA_OPTIONS = ['Sim', 'N√£o']

# Listas de op√ß√µes para os widgets da barra lateral (com a op√ß√£o "Sem Label")
PAISES_OPTIONS = [SEM_PAIS] + PAISES
METODOLOGIAS_OPTIONS = [SEM_METODOLOGIA] + METODOLOGIAS
TIPOS_ESTUDO_OPTIONS = [SEM_TIPO_ESTUDO] + TIPOS_ESTUDO
EIXOS_MATRIZ_OPTIONS = [SEM_EIXO_MATRIZ] + EIXOS_MATRIZ
IDIOMAS_OPTIONS = [SEM_IDIOMA] + IDIOMAS
PEROLA_FILTER_OPTIONS = ['Ambos'] + PEROLA_OPTIONS

# --- Barra Lateral de Filtros ---
st.sidebar.header("‚öôÔ∏è Filtros")

selected_reviewers = st.sidebar.multiselect("Revisor(a)", all_reviewers)
selected_paises = st.sidebar.multiselect("Pa√≠s", PAISES_OPTIONS)
selected_metodologias = st.sidebar.multiselect("Metodologia", METODOLOGIAS_OPTIONS)
selected_tipos_estudo = st.sidebar.multiselect("Tipo de Estudo", TIPOS_ESTUDO_OPTIONS)
selected_eixos_matriz = st.sidebar.multiselect("Eixo Matriz", EIXOS_MATRIZ_OPTIONS)
selected_idiomas = st.sidebar.multiselect("Idioma", IDIOMAS_OPTIONS)
selected_perola = st.sidebar.selectbox("P√©rola", PEROLA_FILTER_OPTIONS, index=0)

# --- L√≥gica de Filtragem Avan√ßada ---
filtered_df = df.copy()

def apply_filter_logic(df, selected_options, all_category_options, no_label_string):
    """
    Aplica a l√≥gica de filtro para uma categoria, lidando com a sele√ß√£o de "Sem Label".
    """
    if not selected_options:
        return df

    sem_label_selected = no_label_string in selected_options
    specific_labels_selected = [opt for opt in selected_options if opt != no_label_string]
    all_category_options_lower = {opt.lower().strip() for opt in all_category_options}

    def check_row(article_labels):
        article_labels_lower = {label.lower().strip() for label in article_labels}
        
        # Condi√ß√£o 1: O artigo N√ÉO tem nenhuma label desta categoria
        has_no_category_label = not any(label in all_category_options_lower for label in article_labels_lower)
        
        # Condi√ß√£o 2: O artigo tem pelo menos uma das labels espec√≠ficas selecionadas
        has_specific_label = any(label.lower().strip() in article_labels_lower for label in specific_labels_selected)

        # L√≥gica final
        if sem_label_selected and specific_labels_selected:
            return has_no_category_label or has_specific_label
        elif sem_label_selected:
            return has_no_category_label
        elif specific_labels_selected:
            return has_specific_label
        return True

    return df[df['Parsed_Labels'].apply(check_row)]

# Aplica o filtro de revisores
if selected_reviewers:
    filtered_df = filtered_df[filtered_df['Reviewers'].apply(lambda x: any(rev in x for rev in selected_reviewers))]

# Aplica os outros filtros um a um
filtered_df = apply_filter_logic(filtered_df, selected_paises, PAISES, SEM_PAIS)
filtered_df = apply_filter_logic(filtered_df, selected_metodologias, METODOLOGIAS, SEM_METODOLOGIA)
filtered_df = apply_filter_logic(filtered_df, selected_tipos_estudo, TIPOS_ESTUDO, SEM_TIPO_ESTUDO)
filtered_df = apply_filter_logic(filtered_df, selected_eixos_matriz, EIXOS_MATRIZ, SEM_EIXO_MATRIZ)
filtered_df = apply_filter_logic(filtered_df, selected_idiomas, IDIOMAS, SEM_IDIOMA)

# Aplica o filtro de P√©rola
if selected_perola != 'Ambos':
    filtered_df = filtered_df[filtered_df['Is_Perola'] == selected_perola]

# --- Fun√ß√£o para preparar o DataFrame para exporta√ß√£o ---
def create_export_df(df_filtered):
    """
    Cria um novo DataFrame com as colunas espec√≠ficas para exporta√ß√£o.
    As colunas s√£o reordenadas conforme a solicita√ß√£o do usu√°rio.
    """
    export_data = []
    for _, row in df_filtered.iterrows():
        # Extrai labels espec√≠ficas para as colunas
        country = next((label for label in row['Parsed_Labels'] if label in PAISES), 'N√£o informado')
        study_type = next((label for label in row['Parsed_Labels'] if label in TIPOS_ESTUDO), 'N√£o informado')
        methodology = next((label for label in row['Parsed_Labels'] if label in METODOLOGIAS), 'N√£o informado')
        eixo_matriz = next((label for label in row['Parsed_Labels'] if label in EIXOS_MATRIZ), 'N√£o informado')
        idioma = next((label for label in row['Parsed_Labels'] if label in IDIOMAS), 'N√£o informado')
        
        export_row = {
            'T√≠tulo estudo': row['title'],
            'Autor(es)': row['authors'],
            'Ano': int(row['year']) if pd.notna(row['year']) else 'N√£o informado',
            'Pa√≠s': country,
            'Tipo de estudo': study_type,
            'Metodologia': methodology,
            'Eixo Matriz': eixo_matriz,
            'Idioma': idioma,
            'Principais resultados': '',
            'P√©rola': row['Is_Perola'],
            'Revisor(es)': ', '.join(row['Reviewers']) if row['Reviewers'] else 'Nenhum'
        }
        export_data.append(export_row)
    
    # Cria o DataFrame com a ordem de colunas desejada
    columns_order = [
        'T√≠tulo estudo', 'Autor(es)', 'Ano', 'Pa√≠s', 'Tipo de estudo',
        'Metodologia', 'Eixo Matriz', 'Idioma', 'Principais resultados', 'P√©rola', 'Revisor(es)'
    ]
    
    return pd.DataFrame(export_data, columns=columns_order)

# --- Se√ß√£o: Gr√°ficos de Resumo no Topo ---
if not filtered_df.empty:
    st.header("üìä Vis√£o Geral dos Resultados Filtrados")
    
    # Prepara os dados para exporta√ß√£o para XLSX
    df_export = create_export_df(filtered_df)
    output = io.BytesIO()
    df_export.to_excel(output, index=False, engine='openpyxl')
    processed_data = output.getvalue()

    st.download_button(
        label="üì• Baixar lista filtrada (.xlsx)",
        data=processed_data,
        file_name='artigos_filtrados.xlsx',
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    )
    
    st.subheader(f"Total de Artigos Encontrados: {len(filtered_df)}")

    filters_to_plot = {
        "Pa√≠s": PAISES,
        "Metodologia": METODOLOGIAS,
        "Tipo de Estudo": TIPOS_ESTUDO,
        "Eixo Matriz": EIXOS_MATRIZ,
        "Idioma": IDIOMAS
    }

    def plot_summary_component(data_frame, filter_name, options_list):
        counts = {}
        for labels_list in data_frame['Parsed_Labels']:
            if isinstance(labels_list, list):
                for label in labels_list:
                    original_label = next((opt for opt in options_list if opt.lower().strip() == label.lower().strip()), None)
                    if original_label:
                        counts[original_label] = counts.get(original_label, 0) + 1
        
        if counts:
            summary_df = pd.DataFrame(counts.items(), columns=['Categoria', 'Contagem']).sort_values(by='Contagem', ascending=False)
            
            if filter_name in ["Metodologia", "Tipo de Estudo"]:
                fig = px.pie(summary_df, values='Contagem', names='Categoria', title=f'Distribui√ß√£o por {filter_name}',
                             color_discrete_sequence=px.colors.sequential.Viridis, hole=0.3)
                fig.update_traces(textposition='inside', textinfo='percent+label', marker=dict(line=dict(color='#000000', width=1)))
            else:
                fig = px.bar(summary_df, x='Categoria', y='Contagem', title=f'Distribui√ß√£o por {filter_name}',
                             labels={'Contagem': 'N¬∫ Artigos', 'Categoria': filter_name},
                             color='Contagem', color_continuous_scale=px.colors.sequential.Viridis)
                fig.update_layout(xaxis_title_text='', yaxis_title_text='N√∫mero de Artigos')
            
            fig.update_layout(height=300, margin=dict(l=0, r=0, t=40, b=0))
            return fig
        return None

    filter_names = list(filters_to_plot.keys())
    for i in range(0, len(filter_names), 2):
        cols = st.columns(2)
        for j in range(2):
            if i + j < len(filter_names):
                name = filter_names[i + j]
                fig = plot_summary_component(filtered_df, name, filters_to_plot[name])
                if fig:
                    cols[j].plotly_chart(fig, use_container_width=True)

    # --- Se√ß√£o da WordCloud ---
    st.header("‚òÅÔ∏è Nuvem de Palavras dos Resumos Filtrados")
    
    # Conjuntos gramaticais a excluir para a WordCloud
    PALAVRAS_EXCLUIR = set(stopwords.words('portuguese')).union({
        'eu', 'tu', 'ele', 'ela', 'n√≥s', 'v√≥s', 'eles', 'elas', 'me', 'te', 'se', 'nos', 'vos', 'lhe', 'lhes',
        'mim', 'ti', 'si', 'comigo', 'contigo', 'consigo', 'meu', 'minha', 'meus', 'minhas', 'teu', 'tua',
        'teus', 'tuas', 'seu', 'sua', 'seus', 'suas', 'nosso', 'nossa', 'nossos', 'nossas', 'vosso', 'vossa',
        'vossos', 'vossas', 'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses', 'essas', 'aquele',
        'aquela', 'aqueles', 'aquelas', 'isto', 'isso', 'aquilo', 'algu√©m', 'ningu√©m', 'tudo', 'nada', 'cada',
        'quem', 'qual', 'quais', 'quanto', 'quantos', 'quanta', 'quantas', 'algum', 'alguma', 'alguns',
        'algumas', 'nenhum', 'nenhuma', 'uns', 'umas', 'a', 'ante', 'ap√≥s', 'at√©', 'com', 'contra', 'de',
        'desde', 'em', 'entre', 'para', 'per', 'perante', 'por', 'sem', 'sob', 'sobre', 'tr√°s', 'aqui', 'ali',
        'l√°', 'c√°', 'acol√°', 'a√≠', 'perto', 'longe', 'dentro', 'fora', 'acima', 'abaixo', 'atr√°s', 'adiante',
        'antes', 'depois', 'cedo', 'tarde', 'logo', 'j√°', 'ainda', 'sempre', 'nunca', 'jamais', 'eventualmente',
        'provavelmente', 'possivelmente', 'certamente', 'sim', 'n√£o', 'tamb√©m', 's√≥', 'apenas', 'quase',
        'muito', 'pouco', 'bastante', 'demais', 'tanto', 'quanto', 'mais', 'menos', 'mal', 'bem', 'melhor',
        'pior', 'devagar', 'depressa', 'calmamente', 'rapidamente', 'do', 'da', 'dos', 'das', 'no', 'na',
        'nos', 'nas', 'pelo', 'pela', 'pelos', 'pelas', 'deste', 'desta', 'desses', 'dessas', 'neste',
        'nesta', 'nestes', 'nestas', 'daquele', 'daquela', 'daqueles', 'daquelas', '√†', '√†s', 'ao', 'aos'
    })

    def filtrar_palavras(texto):
        tokenizer = RegexpTokenizer(r'\b\w+\b')
        palavras = tokenizer.tokenize(texto.lower())
        return [
            palavra for palavra in palavras
            if palavra.isalpha() and len(palavra) >= 4 and palavra not in PALAVRAS_EXCLUIR
        ]

    def gerar_wordcloud(palavras_filtradas):
        if not palavras_filtradas:
            return None
        texto_filtrado = ' '.join(palavras_filtradas)
        wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS,
                              max_words=200, colormap='viridis', collocations=False).generate(texto_filtrado)
        fig, ax = plt.subplots(figsize=(10, 5), facecolor=None)
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis("off")
        plt.tight_layout(pad=0)
        return fig

    all_abstracts_text = " ".join(filtered_df['abstract'].dropna().tolist())
    if all_abstracts_text.strip():
        palavras_filtradas = filtrar_palavras(all_abstracts_text)
        if palavras_filtradas:
            wordcloud_fig = gerar_wordcloud(palavras_filtradas)
            if wordcloud_fig:
                st.pyplot(wordcloud_fig)
                plt.close(wordcloud_fig)
            else:
                st.info("Nenhuma palavra significativa encontrada para gerar a nuvem de palavras.")
        else:
            st.info("Nenhuma palavra significativa encontrada para gerar a nuvem de palavras ap√≥s a filtragem.")
    else:
        st.info("Nenhum resumo dispon√≠vel nos artigos filtrados para gerar a nuvem de palavras.")

    # --- Resultados Detalhados dos Artigos ---
    st.subheader(f"üîé Artigos Encontrados ({len(filtered_df)})")
    for _, row in filtered_df.iterrows():
        st.markdown("---")
        st.markdown(f"**T√≠tulo:** {row['title']}")
        st.markdown(f"**Autores:** {row['authors']}")
        st.markdown(f"**Ano:** {int(row['year']) if pd.notna(row['year']) else 'N√£o informado'}")
        st.markdown(f"**P√©rola:** {row['Is_Perola']}")
        st.markdown(f"**Revisores:** {', '.join(row['Reviewers']) if row['Reviewers'] else 'Nenhum'}")
        st.markdown(f"**Labels:** {', '.join(row['Parsed_Labels']) if row['Parsed_Labels'] else 'Nenhum'}")

        if row['abstract'].strip():
            with st.expander("Ver Resumo"):
                st.write(row['abstract'])
        
        if row['url'] and row['url'].strip():
            st.markdown(f"[üîó Link para o Artigo]({row['url']})")
        
        if row['PDF files'] and row['PDF files'].strip():
            st.info(f"üìÑ PDF dispon√≠vel: {row['PDF files']}")
else:
    st.info("Nenhum artigo encontrado com os filtros selecionados. Ajuste os filtros na barra lateral.")

st.markdown("---")
# --- Pr√≥ximos Passos e Sugest√µes ---
st.header("üí° Pr√≥ximos Passos e Sugest√µes para Aprimoramento")
st.markdown("""
* **Gr√°ficos de Treemap/Sunburst:** Explore o uso de `plotly.express.treemap` ou `plotly.express.sunburst` para visualizar dados hier√°rquicos.
* **Filtros Interativos nos Gr√°ficos:** Implemente a funcionalidade de clicar em uma barra ou fatia do gr√°fico para filtrar os artigos.
* **Tabela Interativa para Artigos:** Utilize `st.dataframe` para apresentar os resultados em uma tabela interativa com busca e classifica√ß√£o.
* **Funcionalidade de Busca por Texto:** Inclua uma caixa de texto para pesquisar por palavras-chave no t√≠tulo, resumo ou autores.
""")
st.caption("üîß Desenvolvido com Streamlit e Plotly")
c
